<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Experience | Woan-Shiuan Chien</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="shortcut icon" type="image/x-icon" href="../favicon.ico">

  <!-- fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=DM+Serif+Text:ital@0;1&family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">

  <!-- CSS -->
  <link rel="stylesheet" href="../css/animate.css">
  <link rel="stylesheet" href="../css/icomoon.css">
  <link rel="stylesheet" href="../css/bootstrap.css">
  <link rel="stylesheet" href="../css/flexslider.css">
  <link rel="stylesheet" href="../fonts/flaticon/font/flaticon.css">
  <link rel="stylesheet" href="../css/owl.carousel.min.css">
  <link rel="stylesheet" href="../css/owl.theme.default.min.css">
  <link rel="stylesheet" href="../css/style.css">

  <script src="../js/modernizr-2.6.2.min.js"></script>
  <!--[if lt IE 9]>
    <script src="../js/respond.min.js"></script>
  <![endif]-->
</head>

<body>
  <div id="colorlib-page">
    <div class="container-wrap">

      <a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar"
         aria-expanded="false" aria-controls="navbar"><i></i></a>

      <!-- ================== SIDEBAR ================== -->
      <aside id="colorlib-aside" role="complementary" class="border js-fullheight">
        <div class="text-center">
          <div class="author-img" style="background-image: url(../images/profile.jpg);"></div>
          <h1 id="colorlib-logo"><a href="../index.html">Woan-Shiuan Chien</a></h1>
          <span class="position">
            <a href="#">Assistant Professor</a><br>
            @ <a href="#" target="_blank" rel="noopener">Social Lab, NYCU</a>
          </span>
        </div>

        <nav id="colorlib-main-menu" role="navigation" class="navbar">
          <div id="navbar" class="collapse">
            <ul>
              <!-- 在獨立頁面，Home/About/News/Experience 建議都回到 index.html -->
              <li><a href="../index.html#about" class="external">About Me</a></li>
              <li><a href="../index.html#LatestNews" class="external">Latest News</a></li>
			  <li class="active"><a href="experience.html">Experience</a></li>
			  <li><a href="publication.html" class="external">Publication</a></li>	
			  <li><a href="../index.html#Contact" class="external">Contact</a></li>			  
		 
            </ul>
          </div>
        </nav>

        <nav id="colorlib-main-menu" style="padding-bottom: 20%">
          <div class="colorlib-footer">
			  <ul>
				<li><a href="https://scholar.google.com.tw/citations?user=udbwr2sAAAAJ&hl=zh-TW&authuser=1" target="_blank"><i class="fa-brands fa-google-scholar"></i></a></li>
				<li><a href="https://orcid.org/my-orcid?orcid=0000-0003-2235-4080" target="_blank"><i class="fa-brands fa-orcid"></i></a></li>
				<li><a href="https://www.scopus.com/authid/detail.uri?authorId=57203713867" target="_blank"><i class="fa-solid fa-book"></i></a></li>
				<li><a href="https://github.com/woanshiuanchien" target="_blank" rel="noopener"><i class="icon-github"></i></a></li>
				<li><a href="https://www.linkedin.com/in/woan-shiuan-chien-3ab8641ba/"><i class="icon-linkedin2"></i></a></li>
			  </ul>
          </div>
        </nav>

        <div class="colorlib-footer">
          <p>
            <small>
              &copy; Copyright
              <script>document.write(new Date().getFullYear());</script>
              All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by
              <a href="https://colorlib.com" target="_blank" rel="noopener">Colorlib</a>
            </small>
          </p>
        </div>
      </aside>

      <!-- ================== MAIN ================== -->
      <div id="colorlib-main">

			<section class="colorlib-experience" data-section="experience" id="experience">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box">
							<span class="heading-meta">Experience</span>
							<h2 class="colorlib-heading">WORKING EXPERIENCES</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">

							<article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-4">
					                  <i class="icon-briefcase"></i>
					               </div>
								   
									<div class="timeline-label">
									  <h2><b>Behavioral Information &amp; Interaction Computation Lab, NTHU</b></a> <span>2025.04 - Present</span></h2>
									  <p class="small-caps">Postdoctoral Researcher working with Professor <a href="https://biic.ee.nthu.edu.tw/biicers.php">Chi-Chun Lee (Jeremy)</a></p>

									<div>
									<p><b>Research in Modeling Emotions in Interactive and Multimodal Contexts</b></p>
									<ul>
									  <li>Lead the development of a large-scale multimodal interaction corpus capturing co-speech gestures, full-body motion, and expressive speech during dyadic conversations, in collaboration with experts in acting and behavioral sciences.</li>
									  <li>Design affective computing frameworks that move beyond static, unimodal processing by modeling dynamic emotion co-regulation, turn-taking cues, and gestural-prosodic synchrony in real-time interactions.</li>
									</ul>
									</div><div>
									<p><b>Research in Trustworthy AI on Emotion Recognition and Healthcare</b></p>
										<ul>
										  <li>Advance fairness-aware learning across heterogeneous signals. Design and evaluate fairness-aware models for both speech and physiological signals, tackling demographic imbalance and individual variability.</li>
										  <li>Mitigate reliability challenges under real-world data constraints and address incomplete or noisy input conditions through adaptive model design.</li>
										  <li>Investigate how fairness and uncertainty modeling contribute to the trustworthiness of affective systems deployed in sensitive domains such as healthcare and mental wellbeing.</li>
										</ul>
									</div></div></div>
					         </article>



							<article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-3">
					                  <i class="icon-briefcase"></i>
					               </div>
					               <div class="timeline-label">
					                  <h2><a href="https://www.airc.aist.go.jp/en/"><b>National Institute of Advanced Industrial Science and Technology (AIST)</b></a> <span>2024.01 - 2024.03</span></h2>
										<p class="small-caps">Visiting scholar at Artificial Intelligence Research Center (AIRC)</p>
										<ul><p><li>Consider emotion recognition of the interlocutor in dialogue system</li></p></ul>
					               </div>

					            </div>
					         </article>
					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-2">
									<i class="icon-briefcase"></i>

					               </div>
					               <div class="timeline-label">

										<h2><a href="https://www.itri.org.tw/english/"><b>Industrial Technology Research Institute (ITRI)</b></a> <span>2021.06 - 2021.08</span></h2>
										<p class="small-caps">AI Medical Imaging Algorithm Intern</p>
										<ul><p><li>Implement Graph Neural Networks on Electric Health Records</li></p></ul>
									</div>
					            </div>
					         </article>
					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									<i class="icon-briefcase"></i>
					               </div>

					               <div class="timeline-label">

										<h2><a href="https://www.nuvoton.com/"><b>Nuvoton Technology Corporation (Nuvoton Crop.)</b></a> <span>2017.10 - 2019.09</span></h2>
										<p class="small-caps">Microcontroller System Application Engineer</p>
										<ul><p><li>Mini-PCIe Expansion Adapter Boards (NB-IoT, LTE, LoRa Gateway)</li>
										<li>Key Word Spotting (Speech Recognition) featuring the NuMicro M480 series microcontroller</li>
										<li>Digital Image Recognition System featuring the NuMicro M480 series microcontroller</li>
										<li>OLED Display with GIF Format Decode featuring the NuMicro M480 series microcontroller</li></p></ul>
					               </div>
					            </div>
					         </article>


					         <article class="timeline-entry begin animate-box" data-animate-effect="fadeInBottom">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-none">
					               </div>
					            </div>
					         </article>
					      
					      </div>
	


							<h2 class="colorlib-heading animate-box">COOPERATED PROJECTS</h2>

					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">
						<article class="timeline-entry animate-box">
							<div class="timeline-entry-inner">

								<div class="timeline-icon color-2">
									<i class="icon-paper"></i>
								</div>

								<div class="timeline-label">
									<details>
										<summary>
											<h2><b>Interactive Content Design Laboratory (Icd Lab.), <a href="https://www.tohoku.ac.jp/en/">Tohoku University</a>, Japan</b> <span>2025.04 - Present</span><p class="faq-plus">&plus;</p></h2>
										</summary>
										<p><b>Collaborator:</b> Professor <a href="#">Miao Cheng</a>, <a href="#">Chia-Huei Tseng</a> (Research Institute of Electrical Communication, Tohoku University)</p>
										<ul>
											<li>Initiate a new collaborative project to collect a large-scale VICON-based 3D motion capture database focused on emotional expressions during naturalistic interactions, integrating body gestures, speech, and emotional annotations.</li>
											<li>Design continuous emotion annotation protocols across self, partner, and observer perspectives, aimed at enabling fine-grained multimodal analysis of dynamic emotional states for embodied AI applications.</li>
										</ul>
									</details>
								</div>
							</div>
						</article>

						<article class="timeline-entry animate-box">
							<div class="timeline-entry-inner">

								<div class="timeline-icon color-3">
									<i class="icon-paper"></i>
								</div>

								<div class="timeline-label">
									<details>
										<summary>
											<h2><b>Multimodal Signal Processing Laboratory (MSP Lab.), <a href="https://www.cmu.edu/">Carnegie Mellon University (CMU)</a>, USA</b> <span>2025.01 - Present</span><p class="faq-plus">&plus;</p></h2>
										</summary>
										<p><b>Collaborator:</b> Professor <a href="https://carlosbusso.com/">Carlos Busso</a> (Language Technologies Institute (LTI), CMU)</p>
										<ul>
											<li>Work on developing a large language model (LLM)-based annotation framework to support emotion retrieval in dyadic interaction datasets.</li>
										</ul>
									</details>
								</div>
							</div>
						</article>

							<article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-2">
									<i class="icon-paper"></i>
					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="https://www.nstc.gov.tw/"><b>National Science and Technology Council: AI Innovation Research Center Project</b></a> <span>2022.02 - 2025.07</span><p class="faq-plus">&plus;</p></h2>
											</summary>
	
											<p><li>Advanced Technologies for Designing Trustable AI Services.</li>
											<li>Toward Realizing Into-Life Emotion AI through Robust, Scalable, and Trustworthy Affective Signal Modeling.</li></p>
										</details>
					               </div>
					            </div>
					         </article>
					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-3">
									<i class="icon-paper"></i>

					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="https://www.qualcomm.com/"><b>Qualcomm Incorporation, USA</b></a> <span>2022.08 - 2024.06</span><p class="faq-plus">&plus;</p></h2>
											</summary>
					                  		<p><li>Distributed learning for edge AI applications.</li>
									 		 <li>Developing in-car automatic speech recognition and driver behavior recognition to enhance vehicle safety.</li></p>
										</details>
					               </div>
					            </div>
					         </article>
					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-2">
									<i class="icon-paper"></i>

					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
					                 			<h2><a href="https://ecs.utdallas.edu/research/researchlabs/msp-lab/"><b>Multimodal Signal Processing Laboratory (MSP Lab.), The University of Texas at Dallas</b></a> <span>2021.03 - Now</span><p class="faq-plus">&plus;</p></h2>
											</summary>
											<p><li>Propose the design of the affective naturalistic database consortium (AndC) with a customizable-standard framework for intelligently-controlled emotional data collection.</li>
									  		<li>Present as a case study the development of a naturalistic large-scale Taiwanese Mandarin podcast corpus using the customizable-standard intelligently-controlled framework.</li></p>
										</details>
					               </div>
					            </div>
					         </article>

					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-3">
									<i class="icon-paper"></i>

					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
											<h2><a href="https://www.qualcomm.com/"><b>Qualcomm Incorporation, USA</b></a> <span>2022.01 - 2022.10</span><p class="faq-plus">&plus;</p></h2>
											</summary>
											<p><li>Stress prediction using bio-signals with federated learning.</li></p>
										</details>
									</div>
					            </div>
					         </article>


					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-2">
									<i class="icon-paper"></i>

					               </div>
					               <div class="timeline-label">
										<details>
											<summary>
					               				<h2><a href="https://www.cmedia.com.tw/"><b>C-Media Electronics Incorporation (C-Media Inc.)</b></a> <span>2020.07 - 2021.01</span><p class="faq-plus">&plus;</p></h2>
											</summary>
					                  		<p><li>Implement AI de-reverberation de-noise algorithm based on deep noise suppression.</li></p>
										</details>
					               </div>
					            </div>
					         </article>

					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
									<i class="icon-paper"></i>

					               </div>
					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="https://web.iii.org.tw/"><b>Institute for Information Industry (III)</b></a> <span>2020.05 - 2020.11</span><p class="faq-plus">&plus;</p></h2>
											</summary>
											<p><li>Develop a computer vision-based video retrieval system speeding up the fakenews screening process.</li>
											<li>The system would be deployed by two NGO fakenews checkers Taiwan FactCheck Center and MyGoPen.</li></p>
										</details>
									</div>
					            </div>
					         </article>

					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-none">
					               </div>
					            </div>
					         </article>
					      </div>
					   </div>
				   </div>
				   
							<h2 class="colorlib-heading animate-box">Teaching</h2>

					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">


					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-2">
					                  <i class="icon-book2"></i>
					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="https://www.futurelearn.com/"><b>Future Learn, Massive Open Online Course (MOOC)</b></a><p class="faq-plus">&plus;</p></h2>
												<p class="small-caps">Teatching Material Designing Assistant</p>
											</summary>

											<div><p><li>Deconstructing Research : How to Read and Write a Research Paper (2023, 2024)</li></p></div>
										</details>
					            </div>
					         </article>


					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-4">
					                  <i class="icon-book2"></i>
					               </div>

					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="#"><b>National Tsing Hua University</b></a><p class="faq-plus">&plus;</p></h2>
												<p class="small-caps">Teatching Assistant</p>
											</summary>

											<div><p>
											<li>THC1024 Reliable Industrial Wireless Network Technology and Application (2023)</li>
											<li>EE 3700 Introduction to Machine Learning (2022)</li>
											<li>EE 3660 Introduction to Digital Signal Processing (2022)</li>
											<li>EE 3900 Special Topic on Implementation (2021, 2022, 2023)</li>
											<li>EECS 3010 Industry Internship (2021, 2022, 2023)</li>
											<li>EE 3662 Digital Signal Processing Laboratory (2020)</li></p>
											</div>
										</details>
					            </div>
					         </article>


					         <article class="timeline-entry animate-box">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-3">
					                  <i class="icon-book2"></i>
					               </div>
					               <div class="timeline-label">
										<details>
											<summary>
												<h2><a href="#"><b>National Chung Cheng University</b></a><p class="faq-plus">&plus;</p></h2>
												<p class="small-caps"> Teatching Assistant</p>
											</summary>

											<div><p><li>EE 4156114 Biomedical Signal Processing (2017)</li>
											<li>EE 4151004 Introduction to Computers (2016)</li>
											<li>EE 4153013 Digital Signal Processing Laboratory (2016)</li>
											<li>EE 4153213 Introduction to Digital Signal Processing (2016)</li></p>
										    </div>
										</details>
					            </div>
					         </article>				   
				   
					         <article class="timeline-entry begin animate-box" data-animate-effect="fadeInBottom">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-none">
					               </div></div>
					         </article>
					      </div>
					   </div>
				   </div>				   
				</div>
			</section>

      </div><!-- end: colorlib-main -->

    </div><!-- end: container-wrap -->
  </div><!-- end: colorlib-page -->

  <!-- JS -->
  <script src="../js/jquery.min.js"></script>
  <script src="../js/jquery.easing.1.3.js"></script>
  <script src="../js/bootstrap.min.js"></script>
  <script src="../js/jquery.waypoints.min.js"></script>
  <script src="../js/jquery.flexslider-min.js"></script>
  <script src="../js/owl.carousel.min.js"></script>
  <script src="../js/jquery.countTo.js"></script>
  <script src="../js/main.js"></script>
</body>
</html>
